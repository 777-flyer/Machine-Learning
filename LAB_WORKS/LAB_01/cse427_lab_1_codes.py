# -*- coding: utf-8 -*-
"""CSE427 Lab 1 Codes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17ee-XBIfcgZ5iM6PZlk3q6srDjuj1xWz

# **CSE427 Machine Learning Lab - Data Manipulation Essentials**

# **Topic: NumPy, Pandas, and Matplotlib Fundamentals for ML**

# Numpy
"""

import numpy as np

# Create array from list
list1 = [1, 2, 3, 4, 5]
arr1 = np.array(list1)
print("Array from list:", arr1)

# Create zero array - useful for initialization
arr2 = np.zeros(5)
print("Zero array:", arr2)
print("Data type:", arr2.dtype)

# Create ones array - useful for bias initialization
arr_ones = np.ones((3, 3))
print("Ones array:\n", arr_ones)

# Create array with specific value - useful for constant initialization
arr_full = np.full((2, 3), 7)
print("Array filled with 7:\n", arr_full)

# --- Matrix Operations ---

list5 = np.array([[1, 2, 3],
                  [4, 5, 6]])
list6 = np.array([[1, 2, 3],
                  [4, 5, 6]])

# Element-wise operations
print("Element-wise addition:\n", list5 + list6)
print("Element-wise subtraction:\n", list5 - list6)
print("Element-wise multiplication:\n", list5 * list6)
print("Element-wise division:\n", list5 / list6)

# Matrix multiplication - crucial for neural networks
arr1 = np.array([[1, 2], [8, 6]])    # (2, 2)
arr2 = np.array([[4, 5], [4, 9]])    #  (2, 2)

print("Matrix multiplication (@ operator):\n", arr1 @ arr2)
print("Matrix multiplication (dot):\n", arr1.dot(arr2))
print("Matrix multiplication (matmul):\n", np.matmul(arr1, arr2))

# Transpose - flips rows and columns
arr1 = np.array([[1, 2], [8, 6]])
print("Original:\n", arr1)
print("Transposed:\n", arr1.T)

# Aggregation Functions

arr1 = np.array([[1, 2], [8, 6]])
print("Sum of all elements:", arr1.sum())
print("Sum along columns (axis=0):", arr1.sum(axis=0))
print("Sum along rows (axis=1):", arr1.sum(axis=1))

#shape
arr1 = np.array([[1, 2], [8, 6]])
print(arr1.shape)
#reshape
arr2 = arr1.reshape(4, 1)
print(arr2)

# Other useful aggregations for ML
print("Mean:", arr1.mean())
print("Standard deviation:", arr1.std())
print("Min value:", arr1.min())
print("Max value:", arr1.max())
print("Median:", np.median(arr1))

# arange - creates array with evenly spaced values
arr2 = np.arange(1, 10, 2)  # start, stop, step
print("arange result:", arr2)

# linspace - creates array with specified number of points
arr_linspace = np.linspace(0, 1, 5)  # 5 points between 0 and 1
print("linspace result:", arr_linspace)

#Reshaping

arr1 = np.array([[1, 2], [8, 6]])
print("Original shape:", arr1.shape)

# Reshape - changes dimensions without changing data
arr2 = arr1.reshape(4, 1)
print("Reshaped (4x1):\n", arr2)

# Reshape to 1D
arr3 = arr1.reshape(-1)  # -1 means infer dimension
print("Reshaped to 1D:", arr3)

# Identity matrix - useful for linear algebra operations
arr1 = np.eye(3)
print("Identity matrix (3x3):\n", arr1)

arr2 = np.identity(3)
print("Identity using identity():\n", arr2)

# Identity with offset diagonal
idn = np.eye(N=3, M=4, k=1)
print("Identity with offset:\n", idn)

# Flattening Arrays

arr1 = np.array([[1, 2], [8, 6]])

# flatten - creates a copy of array in 1D
flat1 = arr1.flatten()
print("Flattened (copy):", flat1)

# ravel - returns view (no copy, more memory efficient)
flat2 = arr1.ravel()
print("Raveled (view):", flat2)

# Random uniform distribution
rand_uniform = np.random.rand(3, 3)  # 3x3 array of values between 0-1
print("Random uniform:\n", rand_uniform)

# Random normal distribution - used for weight initialization
rand_normal = np.random.randn(3, 3)  # mean=0, std=1
print("Random normal:\n", rand_normal)

# Random integers - useful for sampling
rand_int = np.random.randint(0, 10, size=(2, 3))
print("Random integers:\n", rand_int)

# Set seed for reproducibility
np.random.seed(42)
reproducible = np.random.rand(2, 2)
print("Reproducible random:\n", reproducible)

arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
print("Original array:\n", arr)

# Boolean indexing - filter elements
mask = arr > 5
print("Elements > 5:", arr[mask])

# Fancy indexing - select specific rows/columns
print("First and third row:", arr[[0, 2], :])

"""# Pandas"""

import pandas as pd

list1 = [1, 2, 3, 4, 5]
ser1 = pd.Series(list1)
print("Series:\n", ser1)
print("Data type:", ser1.dtype)
print("Shape:", ser1.shape)

# Access index and values
print("Index:", ser1.index)
print("Values:", ser1.values)

# Series with custom index
idx = ['a', 'b', 'c', 'd', 'e']
ds = pd.Series(list1, index=idx)
print("Custom indexed series:\n", ds)
print("Access element 'c':", ds['c'])

# Load CSV file
loc = '/content/iris.csv'
df = pd.read_csv(loc)
print("DataFrame loaded:\n", df)

loc = '/content/iris.csv'
df = pd.read_csv(loc)
print(df)

# Get specific number of rows
print("First 10 rows:\n", df.head(10))

# Get DataFrame structure and info
df.info()

# Get statistical summary
print("Statistical summary:\n", df.describe())

# Get column names
print("Columns:", df.columns.tolist())

# Check for null values
print("Null values per column:\n", df.isnull().sum())

# Count non-null values
print("Non-null counts:\n", df.count())

# # Fill missing values with mean
# df_filled = df.fillna(df.mean())

# # Fill with specific value
# df_filled = df.fillna(0)

# # Drop rows with missing values
# df_dropped = df.dropna()

# Value counts - useful for classification problems
print("Class distribution:\n", df.value_counts("variety"))

# Get unique values
print("Unique varieties:", df["variety"].unique())

# Get number of unique values
print("Number of unique varieties:", df["variety"].nunique())

df["New"] = 150 * [10]
df.loc[2, "New"] = None  # Create a missing value
print("Null values:\n", df.isnull().sum())

# Fill missing values with mean
df["New"] = df["New"].fillna(df["New"].mean())
print("After filling:\n", df.isnull().sum())

# Select specific columns
selected_cols = df[['sepal.length', 'sepal.width']]
print("Selected columns:\n", selected_cols.head())

# Filter rows based on condition
filtered = df[df['sepal.length'] > 5.0]
print("Filtered data:\n", filtered.head())

# Multiple conditions
multi_filter = df[(df['sepal.length'] > 5.0) & (df['variety'] == 'Setosa')]

# Group by category and calculate mean
grouped = df.groupby('variety').mean()
print("Grouped mean:\n", grouped)

# Multiple aggregations
agg_result = df.groupby('variety').agg({
    'sepal.length': ['mean', 'std', 'min', 'max'],
    'petal.length': ['mean', 'std']
})
print("Multiple aggregations:\n", agg_result)

# Sort by column
sorted_df = df.sort_values('sepal.length', ascending=False)
print("Sorted by sepal length:\n", sorted_df.head())

# Sort by multiple columns
multi_sort = df.sort_values(['variety', 'sepal.length'])

"""# Matplotlib"""

import matplotlib.pyplot as plt

# --- Basic Line Plot ---

x = np.array([0, 5])
y = np.array([10, 50])
plt.plot(x, y)
plt.title("Basic Line Plot")
plt.xlabel("X-axis")
plt.ylabel("Y-axis")
plt.show()

arr1 = [10, 20, 50, 60, 20, 40]
plt.plot(arr1, marker='o', linestyle='dotted', color='red', linewidth=2)
plt.title("Customized Line Plot")
plt.grid(True)  # grid for better readability
plt.show()

x = np.arange(-10, 11, 1)

plt.figure(figsize=(12, 8))  # Set figure size

# Quadratic function
y1 = x ** 2
plt.subplot(3, 2, 1)
plt.plot(x, y1, 'b-')
plt.title("y = x²")
plt.grid(True)

# Cubic function
y2 = x ** 3
plt.subplot(3, 2, 2)
plt.plot(x, y2, 'g-')
plt.title("y = x³")
plt.grid(True)

# Quartic function
y3 = x ** 4
plt.subplot(3, 2, 3)
plt.plot(x, y3, 'r-')
plt.title("y = x⁴")
plt.grid(True)

# Exponential function
y4 = np.exp(x / 5)
plt.subplot(3, 2, 4)
plt.plot(x, y4, 'm-')
plt.title("y = e^(x/5)")
plt.grid(True)

# Logarithmic function
y5 = np.log(np.abs(x) + 1)
plt.subplot(3, 2, 5)
plt.plot(x, y5, 'c-')
plt.title("y = log(|x| + 1)")
plt.grid(True)

# Sine function
y6 = np.sin(x)
plt.subplot(3, 2, 6)
plt.plot(x, y6, 'orange')
plt.title("y = sin(x)")
plt.grid(True)

plt.tight_layout()  # Adjust spacing between subplots
plt.show()

# --- Histogram (Distribution Analysis) ---

# Normal distribution - useful for understanding data distribution
x = np.random.normal(150, 20, 200)  # mean=150, std=20, 200 samples

plt.figure(figsize=(8, 6))
plt.hist(x, bins=20, color='skyblue', edgecolor='black', alpha=0.7)
plt.title("Normal Distribution (μ=150, σ=20)")
plt.xlabel("Value")
plt.ylabel("Frequency")
plt.axvline(x.mean(), color='red', linestyle='dashed', linewidth=2, label='Mean')
plt.legend()
plt.show()

# --- Scatter Plot (Feature Relationships) ---

# Useful for visualizing correlations
x_scatter = np.random.rand(100)
y_scatter = 2 * x_scatter + np.random.randn(100) * 0.1

plt.figure(figsize=(8, 6))
plt.scatter(x_scatter, y_scatter, alpha=0.6, c=y_scatter, cmap='viridis')
plt.title("Scatter Plot - Feature Correlation")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.colorbar(label="Value")
plt.show()

# --- Box Plot (Outlier Detection) ---

data = [np.random.normal(0, std, 100) for std in range(1, 4)]

plt.figure(figsize=(8, 6))
plt.boxplot(data, tick_labels=['Group 1', 'Group 2', 'Group 3'])
plt.title("Box Plot - Outlier Detection")
plt.ylabel("Values")
plt.grid(True, alpha=0.3)
plt.show()

# --- Bar Chart (Categorical Data) ---

categories = ['Class A', 'Class B', 'Class C', 'Class D']
values = [25, 40, 30, 45]

plt.figure(figsize=(8, 6))
plt.bar(categories, values, color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A'])
plt.title("Bar Chart - Class Distribution")
plt.xlabel("Classes")
plt.ylabel("Count")
plt.show()

# --- Heatmap (Correlation Matrix) ---

# Create sample correlation matrix
data_matrix = np.random.rand(5, 5)
correlation = np.corrcoef(data_matrix)

plt.figure(figsize=(8, 6))
plt.imshow(correlation, cmap='coolwarm', aspect='auto')
plt.colorbar(label='Correlation')
plt.title("Heatmap - Feature Correlations")
plt.xticks(range(5), [f'F{i}' for i in range(5)])
plt.yticks(range(5), [f'F{i}' for i in range(5)])
plt.show()

# Mount Google Drive to access datasets
from google.colab import drive
drive.mount('/content/drive')